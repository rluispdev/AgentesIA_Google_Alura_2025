{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w0MiixPoianZ"
      },
      "outputs": [],
      "source": [
        "%pip -q install google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "If3m_QyuimJw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "MODEL_VERSION = \"gemini-2.0-flash\""
      ],
      "metadata": {
        "id": "7reCDRBAivZh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from IPython.display import HTML, Markdown\n",
        "\n",
        "result = client.models.generate_content(\n",
        "    model= MODEL_VERSION,\n",
        "    contents ='Quando é a proxima Imersao IA com Google Gemini da Alura?',\n",
        ")\n",
        "\n",
        "# Exibe a resposta na tela\n",
        "display(Markdown(f\"Resposta:\\n {result.text}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "uuBK3gs9jCsp",
        "outputId": "71737774-d034-4369-e6a4-475f3d7241c5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Resposta:\n A Alura não tem uma data fixa para a Imersão IA com Google Gemini. A melhor maneira de saber sobre as próximas edições é:\n\n*   **Acompanhar a página oficial da Alura:** Verifique regularmente a seção de imersões ou cursos de inteligência artificial no site da Alura.\n*   **Assinar a newsletter da Alura:** Assim, você receberá informações sobre os próximos lançamentos e eventos.\n*   **Seguir as redes sociais da Alura:** Eles costumam divulgar as novidades por lá.\n*   **Participar da comunidade da Alura:** Fique de olho nos fóruns e grupos de discussão, onde os alunos compartilham informações sobre os próximos cursos e imersões."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lfiXqB2kl9UM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = client.models.generate_content(\n",
        "    model=MODEL_VERSION,\n",
        "    contents='Quando é a próxima Imersão IA com Google Gemini da Alura?',\n",
        "    config={\"tools\":[{\"google_search\": {}}]}\n",
        ")\n",
        "\n",
        "display(Markdown(f\"Resposta:\\n {result.text}\"))"
      ],
      "metadata": {
        "id": "yXaZd7iZ4ftw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "1060052e-6ecf-4148-cdc7-590709a6cb15"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Resposta:\n A próxima Imersão IA com Google Gemini da Alura já aconteceu entre os dias 12 e 16 de maio de 2025. As inscrições estiveram abertas até o dia 11 de maio de 2025.\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar Framework ADK de agentes do Google\n",
        "!pip install -q google-adk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDcpXqLlnBU2",
        "outputId": "2067f561-ca94-47a3-ecb2-d08d40233e7a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.2 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.1/232.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.1/217.1 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m334.1/334.1 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.1/125.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.adk.agents import Agent\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.tools import google_search\n",
        "from google.genai import types\n",
        "from datetime import date\n",
        "import textwrap\n",
        "from IPython.display import display, Markdown\n",
        "import requests\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "P_O3Wfxhn2oV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def call_agent(agent: Agent, message_text: str) -> str:\n",
        "    session_service = InMemorySessionService()\n",
        "    session = session_service.create_session(app_name=agent.name, user_id=\"user1\", session_id=\"session1\")\n",
        "    runner = Runner(agent=agent, app_name=agent.name, session_service=session_service)\n",
        "    content = types.Content(role=\"user\", parts=[types.Part(text=message_text)])\n",
        "\n",
        "    final_response = \"\"\n",
        "\n",
        "    for event in runner.run(user_id=\"user1\", session_id=\"session1\", new_message=content):\n",
        "        if event.is_final_response():\n",
        "          for part in event.content.parts:\n",
        "            if part.text is not None:\n",
        "              final_response += part.text\n",
        "              final_response += \"\\n\"\n",
        "    return final_response"
      ],
      "metadata": {
        "id": "XS7jmRZKo82-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "E2r1u0QIpTMq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Agente 1: Buscador de Notícias Global ---\n",
        "\n",
        "def agente_buscador(topico, data_de_hoje):\n",
        "  buscador = Agent(\n",
        "      name=\"agente_buscador\",\n",
        "      model= MODEL_VERSION,\n",
        "      instruction= \"\"\"\n",
        "      Você é um assistente de pesquisa global. A sua tarefa é usar a ferramenta de busca do google (google_search)\n",
        "      para recuperar as últimas notícias de lançamentos muitos relavantes sonre o tópico abaixo.\n",
        "      Foque em no máximo em 5 lançamentos relevantes, com base na quantidade e entusiasmo das noticias sobre eles.\n",
        "      Se um tema tiver poucas noticias ou reações entusiamadas, é possivel que ele não seja tão relevante assim e\n",
        "      pode ser substituido por outro tema que tenha mais relevancia.\n",
        "      Esses lancamentos devem ser atuais, de no máximo um mês antes da data de hoje, e caso estejam em ingles ou\n",
        "      qualquer idioma, traduza  para o português brasileiro antes de retornar a notícia.\n",
        "      \"\"\",\n",
        "      description=\"Agente que busca notícias sobre um determinado tópico no Google\",\n",
        "      tools =[google_search],\n",
        "  )\n",
        "\n",
        "\n",
        "  entrada_do_agente_buscador = f\"Tópico {topico}\\nData de Hoje: {data_de_hoje}\"\n",
        "  resposta_do_agente_buscador = call_agent(buscador, entrada_do_agente_buscador)\n",
        "  return resposta_do_agente_buscador\n"
      ],
      "metadata": {
        "id": "6pZBm78apx_9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################\n",
        "# --- Agente 2: Planejador de posts --- #\n",
        "################################################\n",
        "def agente_planejador(topico, lancamentos_buscados):\n",
        "    planejador = Agent(\n",
        "        name=\"agente_planejador\",\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        instruction=\"\"\"\n",
        "        Você é um planejador de conteúdo, especialista em redes socias. Com base na lista lançamentos mais recentes e relevantes\n",
        "        buscador, você deve:\n",
        "        usar a ferramenta do Google(google_search) para criar um plano sobre\n",
        "        quais são os pontos mais relevantes que poderíamos abordar em um post sobre\n",
        "        cada um deles. Você também pode usar o (google_search) para encontrarmais informações sobre os temas e aprovofundar.\n",
        "        Ao final, você pode escolher o tema mais relevante entre eles com base nas suas pesquisas e retornar esse tema, seus pontos\n",
        "        mais relevantes, e a plane com os assuntos a serem abordados no post que será escrito posterioermente.\n",
        "        \"\"\",\n",
        "        description=\"Agente que planeja posts\",\n",
        "        tools=[google_search]\n",
        "    )\n",
        "\n",
        "    entrada_do_agente_planejador = f\"Tópico:{topico}\\nLançamentos buscados: {lancamentos_buscados}\"\n",
        "    plano_do_post = call_agent(planejador, entrada_do_agente_planejador)\n",
        "    return plano_do_post"
      ],
      "metadata": {
        "id": "AGq7VYUKpyi2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################\n",
        "# --- Agente 3: Redator do Post --- #\n",
        "######################################\n",
        "def agente_redator(topico, plano_de_post):\n",
        "    redator = Agent(\n",
        "        name=\"agente_redator\",\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        instruction=\"\"\"\n",
        "            Você é um Redator Criativo especializado em criar posts virais para redes sociais.\n",
        "            Você escreve posts para a empresa Alura, a maior escola online de tecnologia do Brasil.\n",
        "            Utilize o tema fornecido no plano de post e os pontos mais relevantes fornecidos e, com base nisso,\n",
        "            escreva um rascunho de post para Instagram sobre o tema indicado.\n",
        "            O post deve ser engajador, informativo, com linguagem simples e incluir 2 a 4 hashtags no final.\n",
        "            \"\"\",\n",
        "        description=\"Agente redator de posts engajadores para Instagram\"\n",
        "    )\n",
        "    entrada_do_agente_redator = f\"Tópico: {topico}\\nPlano de post: {plano_de_post}\"\n",
        "    # Executa o agente\n",
        "    rascunho = call_agent(redator, entrada_do_agente_redator)\n",
        "    return rascunho"
      ],
      "metadata": {
        "id": "ydyl98vAJ5np"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################\n",
        "# --- Agente 4: Revisor de Qualidade --- #\n",
        "##########################################\n",
        "def agente_revisor(topico, rascunho_gerado):\n",
        "    revisor = Agent(\n",
        "        name=\"agente_revisor\",\n",
        "        model=\"gemini-2.0-flash\",\n",
        "        instruction=\"\"\"\n",
        "            Você é um Editor e Revisor de Conteúdo meticuloso, especializado em posts para redes sociais, com foco no Instagram.\n",
        "            Por ter um público jovem, entre 18 e 30 anos, use um tom de escrita adequado.\n",
        "            Revise o rascunho de post de Instagram abaixo sobre o tópico indicado, verificando clareza, concisão, correção e tom.\n",
        "            Se o rascunho estiver bom, responda apenas 'O rascunho está ótimo e pronto para publicar!'.\n",
        "            Caso haja problemas, aponte-os e sugira melhorias.\n",
        "            \"\"\",\n",
        "        description=\"Agente revisor de post para redes sociais.\"\n",
        "    )\n",
        "    entrada_do_agente_revisor = f\"Tópico: {topico}\\nRascunho: {rascunho_gerado}\"\n",
        "    texto_revisado = call_agent(revisor, entrada_do_agente_revisor)\n",
        "    return texto_revisado"
      ],
      "metadata": {
        "id": "lYaA8o5VKaDR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_de_hoje = date.today().strftime(\"%d/%m/%Y\")\n",
        "\n",
        "print(\"🚀 Iniciando o Sistema de Criação de Posts para Instagram com 4 Agentes 🚀\")\n",
        "\n",
        "\n",
        "topico = input(\"❓ Por favor, digite o TÓPICO sobre o qual você quer criar o post de tendências: \")\n",
        "\n",
        "\n",
        "if not topico:\n",
        "  print(\"Digite por favor  o tópico desejado.\")\n",
        "else:\n",
        "  print(f\"ótimo, Vamos criar o post sobre novidades em {topico}\")\n",
        "\n",
        "  lacamentos = agente_buscador(topico, data_de_hoje)\n",
        "  plano_de_post = agente_planejador(topico, lacamentos)\n",
        "  rascunho_de_post = agente_planejador(topico, plano_de_post)\n",
        "  post_final = agente_revisor(topico,rascunho_de_post)\n",
        "\n",
        "display(to_markdown(post_final))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "id": "H0NVjduRKshX",
        "outputId": "b5a124f8-e7aa-4802-be3c-f78e74f52fe8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Iniciando o Sistema de Criação de Posts para Instagram com 4 Agentes 🚀\n",
            "❓ Por favor, digite o TÓPICO sobre o qual você quer criar o post de tendências: modelos de pipas\n",
            "ótimo, Vamos criar o post sobre novidades em modelos de pipas\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-66 (_asyncio_thread_main):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 138, in _asyncio_thread_main\n",
            "    asyncio.run(_invoke_run_async())\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 190, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 654, in run_until_complete\n",
            "    return future.result()\n",
            "           ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 126, in _invoke_run_async\n",
            "    async for event in self.run_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/runners.py\", line 197, in run_async\n",
            "    async for event in invocation_context.agent.run_async(invocation_context):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/agents/base_agent.py\", line 133, in run_async\n",
            "    async for event in self._run_async_impl(ctx):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/agents/llm_agent.py\", line 246, in _run_async_impl\n",
            "    async for event in self._llm_flow.run_async(ctx):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 243, in run_async\n",
            "    async for event in self._run_one_step_async(invocation_context):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 268, in _run_one_step_async\n",
            "    async for llm_response in self._call_llm_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/flows/llm_flows/base_llm_flow.py\", line 483, in _call_llm_async\n",
            "    async for llm_response in llm.generate_content_async(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/adk/models/google_llm.py\", line 140, in generate_content_async\n",
            "    response = await self.api_client.aio.models.generate_content(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/models.py\", line 6672, in generate_content\n",
            "    response = await self._generate_content(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/models.py\", line 5674, in _generate_content\n",
            "    response_dict = await self._api_client.async_request(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\", line 789, in async_request\n",
            "    result = await self._async_request(http_request=http_request, stream=False)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/_api_client.py\", line 733, in _async_request\n",
            "    await errors.APIError.raise_for_async_response(response)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/genai/errors.py\", line 129, in raise_for_async_response\n",
            "    raise ClientError(status_code, response_json, response)\n",
            "google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': \"Gemini 2.5 Pro Preview doesn't have a free quota tier. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\", 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro-exp'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-pro-exp', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro-exp'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerDay-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro-exp'}}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ""
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MFYnKezUOl1f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}